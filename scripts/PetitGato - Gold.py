# Databricks notebook source
# MAGIC %md
# MAGIC ##Validando a SparkSession

# COMMAND ----------

spark

# COMMAND ----------

# MAGIC %md
# MAGIC ##Conectando Azure ADLS Gen2 no Databricks

# COMMAND ----------

# MAGIC %md
# MAGIC ###Mostrando os pontos de montagem no cluster Databricks

# COMMAND ----------

display(dbutils.fs.mounts())

# COMMAND ----------

# MAGIC %md
# MAGIC ### Definindo uma função para montar um ADLS com um ponto de montagem com ADLS SAS 

# COMMAND ----------

storageAccountName = "datalake15b08d56c4920f36"
sasToken = "sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2024-06-29T04:47:37Z&st=2024-06-28T20:47:37Z&spr=https&sig=3759nFSMPBdjIy2lOKOUDv1jGXRaPt%2FRtIEnshqFsFk%3D"

# COMMAND ----------

# MAGIC %md
# MAGIC ### Mostrando todos os arquivos da camada prata

# COMMAND ----------

display(dbutils.fs.ls(f"/mnt/{storageAccountName}/silver"))

# COMMAND ----------

# MAGIC %md
# MAGIC ###Gerando um dataframe dos delta lake no container prata do Azure Data Lake Storage

# COMMAND ----------

df_customerorder = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/customerorder")
df_orderitem     = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/orderitem")
df_item          = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/item")
df_customer      = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/customer")
df_category      = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/category")
df_coffeetable   = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/coffeetable")
df_payment       = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/payment")
df_cat           = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/cat")
df_customercat   = spark.read.format('delta').load(f"/mnt/{storageAccountName}/silver/customercat")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Adicionando metadados de data e hora de processamento e nome do arquivo de origem

# COMMAND ----------

# MAGIC %md
# MAGIC Deletar se existe

# COMMAND ----------

# MAGIC %sql
# MAGIC drop table if exists dim_mesa;
# MAGIC drop table if exists dim_data;
# MAGIC drop table if exists fato_mesa;
# MAGIC drop table if exists fato_mensal;
# MAGIC drop table if exists pedido;
# MAGIC drop table if exists pedido_item;
# MAGIC drop table if exists item;
# MAGIC drop table if exists categoria;
# MAGIC drop table if exists pagamento;
# MAGIC drop table if exists gatos_adotados;
# MAGIC drop table if exists mesa;

# COMMAND ----------

from pyspark.sql.functions import expr, date_format

# Define o intervalo de datas desejado
data_inicial = "2021-06-28"
data_final = "2024-06-28"

# Calcula o número de dias no intervalo
num_dias = spark.sql(f"SELECT datediff('{data_final}', '{data_inicial}')").collect()[0][0]

# Cria um DataFrame com uma coluna contendo uma sequência de datas
df_calendario = spark.range(0, num_dias + 1) \
    .selectExpr(f"date_add(to_date('{data_inicial}'), CAST(id AS INT)) AS Data")

# Extrai os componentes de data
df_tempo = df_calendario.selectExpr(
    "Data",
    "year(Data) AS Ano",
    "month(Data) AS Mes",
       "(CASE month(Data) \
        WHEN 1 THEN 'JANEIRO' \
        WHEN 2 THEN 'FEVEREIRO' \
        WHEN 3 THEN 'MARCO' \
        WHEN 4 THEN 'ABRIL' \
        WHEN 5 THEN 'MAIO' \
        WHEN 6 THEN 'JUNHO' \
        WHEN 7 THEN 'JULHO' \
        WHEN 8 THEN 'AGOSTO' \
        WHEN 9 THEN 'SETEMBRO' \
        WHEN 10 THEN 'OUTUBRO' \
        WHEN 11 THEN 'NOVEMBRO' \
        WHEN 12 THEN 'DEZEMBRO' \
    END) AS NomeMes",
    "day(Data) AS Dia",
    "(CASE dayofweek(Data) \
        WHEN 1 THEN 'DOMINGO' \
        WHEN 2 THEN 'SEGUNDA-FEIRA' \
        WHEN 3 THEN 'TERCA-FEIRA' \
        WHEN 4 THEN 'QUARTA-FEIRA' \
        WHEN 5 THEN 'QUINTA-FEIRA' \
        WHEN 6 THEN 'SEXTA-FEIRA' \
        WHEN 7 THEN 'SABADO' \
    END) AS NomeDiaSemana",
    "dayofweek(Data) AS NumeroDiaSemana"
)

# Exibe o DataFrame resultante
df_tempo.display()

df_tempo.write.option("path", f"/mnt/{storageAccountName}/gold/dim_data").saveAsTable("dim_data", format="delta")


# COMMAND ----------

# MAGIC %sql
# MAGIC CREATE TABLE dim_mesa (
# MAGIC     sk_mesa BIGINT GENERATED BY DEFAULT AS IDENTITY,
# MAGIC     codigo_mesa INT
# MAGIC )
# MAGIC USING delta
# MAGIC LOCATION '/mnt/datalake15b08d56c4920f36/gold/dim_mesa';
# MAGIC

# COMMAND ----------

# MAGIC %sql
# MAGIC CREATE TABLE fato_mesa (
# MAGIC     sk_mesa BIGINT,
# MAGIC     nomemes varchar(50),
# MAGIC     ano INT,
# MAGIC     qtd_rotatividade INT,
# MAGIC     receita_media DECIMAL(10, 2)
# MAGIC )
# MAGIC USING delta
# MAGIC LOCATION '/mnt/datalake15b08d56c4920f36/gold/fato_mesa';
# MAGIC
# MAGIC CREATE TABLE fato_mensal (
# MAGIC     nomemes varchar(50),
# MAGIC     ano INT,
# MAGIC     qtd_pedidos INT,
# MAGIC     valor_total DECIMAL(10, 2)
# MAGIC )
# MAGIC USING delta
# MAGIC LOCATION '/mnt/datalake15b08d56c4920f36/gold/fato_mensal';

# COMMAND ----------

df_customerorder.createOrReplaceTempView("pedido")
df_payment.createOrReplaceTempView("pagamento")
df_orderitem.createOrReplaceTempView("pedido_item")
df_coffeetable.createOrReplaceTempView("mesa")
df_customercat.createOrReplaceTempView("gatos_adotados")
df_item.createOrReplaceTempView("item")
df_category.createOrReplaceTempView("categoria")

# COMMAND ----------

# MAGIC %sql
# MAGIC -- Inserir dados em dim_mesa
# MAGIC WITH mesa_relacional AS(
# MAGIC   select m.codigo_mesa
# MAGIC   from mesa m
# MAGIC )
# MAGIC MERGE INTO dim_mesa as dim
# MAGIC USING
# MAGIC   mesa_relacional as rel
# MAGIC ON rel.codigo_mesa = dim.codigo_mesa
# MAGIC WHEN NOT MATCHED THEN
# MAGIC 	INSERT (codigo_mesa)
# MAGIC 	VALUES (rel.codigo_mesa)

# COMMAND ----------

# MAGIC %sql
# MAGIC -- Inserir dados em fato_mesa
# MAGIC INSERT INTO fato_mesa (sk_mesa, ano, nomemes, qtd_rotatividade, receita_media)
# MAGIC SELECT 
# MAGIC     mesa.sk_mesa AS sk_mesa,
# MAGIC     d.ano,
# MAGIC     d.nomemes,
# MAGIC     COUNT(distinct pd.codigo_pedido) AS qtd_rotatividade,
# MAGIC     AVG(pg.valor) AS receita_media
# MAGIC FROM 
# MAGIC     dim_mesa as mesa
# MAGIC LEFT JOIN 
# MAGIC     pedido as pd ON mesa.codigo_mesa = pd.codigo_mesa
# MAGIC LEFT JOIN 
# MAGIC     dim_data as d ON cast(d.data as date) = cast(pd.data as date)
# MAGIC LEFT JOIN 
# MAGIC     pagamento pg ON pd.codigo_pedido = pg.codigo_pedido
# MAGIC GROUP BY 
# MAGIC     mesa.sk_mesa, d.ano, d.nomemes;
# MAGIC

# COMMAND ----------

# MAGIC %sql
# MAGIC -- Inserir dados em fato_mensal
# MAGIC INSERT INTO fato_mensal (ano, nomemes, qtd_pedidos, valor_total)
# MAGIC SELECT 
# MAGIC     d.ano,
# MAGIC     d.nomemes,
# MAGIC     COUNT(distinct codigo_pedido) AS quantidade_pedidos,
# MAGIC     SUM(valor) AS valor_total
# MAGIC FROM 
# MAGIC     pagamento as pg
# MAGIC JOIN dim_data d on cast(d.data as date) = cast(pg.data as date)
# MAGIC GROUP BY 
# MAGIC     d.ano, d.nomemes;

# COMMAND ----------

# MAGIC %sql
# MAGIC select * from fato_mesa
# MAGIC order by ano desc, nomemes, sk_mesa

# COMMAND ----------

# MAGIC %sql
# MAGIC select * from fato_mensal
# MAGIC order by ano desc, nomemes desc

# COMMAND ----------

# MAGIC %sql
# MAGIC CREATE OR REPLACE TEMP VIEW QUANTIDADE_GATOS_ADOTADOS AS
# MAGIC SELECT COUNT(1) as quantidade_gatos_adotados
# MAGIC FROM gatos_adotados

# COMMAND ----------

# Converter a TempView em um DataFrame
df = spark.sql("SELECT * FROM QUANTIDADE_GATOS_ADOTADOS")
df.display(10)

# COMMAND ----------

# Salvar o DataFrame no formato Delta
df.write.format('delta').save(f"/mnt/{storageAccountName}/gold/quantidade_gatos_adotados")

# COMMAND ----------

# MAGIC %sql
# MAGIC --Margem de lucro;
# MAGIC CREATE OR REPLACE TEMP VIEW Margem_de_lucro AS
# MAGIC SELECT cast(SUM(I.valor * OI.quantidade) - SUM(I.custo * OI.quantidade) as numeric(15,2)) / SUM(I.valor * OI.quantidade) * 100 AS Margem_lucro
# MAGIC FROM pedido_item as OI
# MAGIC JOIN ITEM I ON OI.codigo_item = I.codigo_item;

# COMMAND ----------

# Converter a TempView em um DataFrame
df = spark.sql("SELECT * FROM Margem_de_lucro")
df.display(10)

# COMMAND ----------

# Salvar o DataFrame no formato Delta
df.write.format('delta').save(f"/mnt/{storageAccountName}/gold/Margem_de_lucro")

# COMMAND ----------

# MAGIC %sql
# MAGIC --Taxa de Retorno de Clientes: Percentual de clientes que retornam após a primeira visita.
# MAGIC CREATE OR REPLACE TEMP VIEW Taxa_de_Retorno AS
# MAGIC select 
# MAGIC cast(100 - 
# MAGIC     (select cast(count(1) as numeric(15,2)) 
# MAGIC      from pedido c
# MAGIC      where not exists (select 1 from pedido cc where cc.codigo_cliente = c.codigo_cliente and c.data <> cc.data))
# MAGIC     /(select count(distinct codigo_pedido) from pedido)
# MAGIC     *100 as numeric(15,2)) Taxa_de_Retorno

# COMMAND ----------

# Converter a TempView em um DataFrame
df = spark.sql("SELECT * FROM Taxa_de_Retorno")
df.display(10)

# COMMAND ----------

# Salvar o DataFrame no formato Delta
df.write.format('delta').save(f"/mnt/{storageAccountName}/gold/Taxa_de_Retorno")

# COMMAND ----------

df_payment.display(2)

# COMMAND ----------


df_payment.display(10)

# COMMAND ----------

# MAGIC %sql
# MAGIC --Ticket médio diário: Receita média gerada
# MAGIC CREATE OR REPLACE TEMP VIEW Ticket_medio_diario AS
# MAGIC WITH MEDIADIARIA AS (
# MAGIC     SELECT CAST(CO.DATA AS DATE) AS DATA, 
# MAGIC            SUM(P.valor) AS TOTAL_DIARIO
# MAGIC     FROM pedido CO
# MAGIC     JOIN pagamento P ON CO.codigo_pedido = P.codigo_pedido
# MAGIC     GROUP BY CAST(CO.data AS DATE)
# MAGIC )
# MAGIC SELECT SUM(TOTAL_DIARIO) / COUNT(DISTINCT DATA) AS TICKET_MEDIO_TOTAL
# MAGIC FROM MEDIADIARIA;

# COMMAND ----------

# Converter a TempView em um DataFrame
df = spark.sql("SELECT * FROM Ticket_medio_diario")
df.display(10)

# COMMAND ----------

# Salvar o DataFrame no formato Delta
df.write.format('delta').save(f"/mnt/{storageAccountName}/gold/Ticket_medio_diario")
