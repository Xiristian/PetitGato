{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#petitgato","title":"PetitGato","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o do Projeto PetitGato desenvolvido com base nos sistemas de Banco de Dados 2. Esta documenta\u00e7\u00e3o detalha o processo de constru\u00e7\u00e3o do Data Lake, desde a leitura dos dados at\u00e9 a disponibiliza\u00e7\u00e3o para consumo atrav\u00e9s de um dashboard.</p>"},{"location":"#objetivos-do-projeto","title":"Objetivos do Projeto","text":"<ul> <li>Leitura de dados de um ambiente relacional escolhido.</li> <li>C\u00f3pia para o Data Lake utilizando uma arquitetura Medalh\u00e3o.</li> <li>Transforma\u00e7\u00e3o dos dados utilizando Apache Spark.</li> <li>Disponibiliza\u00e7\u00e3o dos dados em um modelo dimensional ou OBT.</li> <li>Cria\u00e7\u00e3o de KPIs e m\u00e9tricas para um dashboard de visualiza\u00e7\u00e3o.</li> </ul>"},{"location":"#estrutura-da-documentacao","title":"Estrutura da Documenta\u00e7\u00e3o","text":"<p>Esta documenta\u00e7\u00e3o est\u00e1 organizada nas seguintes se\u00e7\u00f5es:</p> <ul> <li>Vis\u00e3o Geral do PipeLine</li> <li>Configura\u00e7\u00e3o Terraform e Datalake</li> <li>Configura\u00e7\u00e3o Inicial do Ambiente</li> <li>Ingest\u00e3o de Dados</li> <li>Transforma\u00e7\u00e3o de Dados com Apache Spark</li> <li>Modelo Dimensional</li> <li>Dashboard e Visualiza\u00e7\u00e3o</li> <li>Tecnologias Utilizadas</li> <li>Contribuidores do Projeto</li> </ul>"},{"location":"azure-data-lake-terraform/","title":"Configura\u00e7\u00e3o do Azure Data Lake e SQL Server com Terraform","text":""},{"location":"azure-data-lake-terraform/#pre-requisitos","title":"Pr\u00e9-Requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de ter instalado e configurado os seguintes itens:</p> <ul> <li>Azure CLI</li> <li>Visual Studio Code</li> <li>Terraform</li> <li>Conta Microsoft Learning (assinatura sandbox)</li> </ul>"},{"location":"azure-data-lake-terraform/#passos","title":"Passos","text":""},{"location":"azure-data-lake-terraform/#1-ativar-uma-assinatura-de-teste","title":"1. Ativar uma Assinatura de Teste","text":"<p>Utilize a assinatura MS Learn Sandbox para limitar o tempo de uso.</p>"},{"location":"azure-data-lake-terraform/#2-configuracao-da-azure-cli","title":"2. Configura\u00e7\u00e3o da Azure CLI","text":"<p>Antes de iniciar, clone o projeto contendo os arquivos <code>.tf</code> e abra-o no Visual Studio Code.</p>"},{"location":"azure-data-lake-terraform/#21-login-na-azure-cli","title":"2.1 Login na Azure CLI","text":"<pre><code>az login\n</code></pre>"},{"location":"azure-data-lake-terraform/#22-obter-o-nome-do-grupo-de-recursos","title":"2.2 Obter o Nome do Grupo de Recursos","text":"<pre><code>az group list -o table\n</code></pre>"},{"location":"azure-data-lake-terraform/#22-obter-o-nome-do-grupo-de-recursos_1","title":"2.2 Obter o Nome do Grupo de Recursos","text":"<pre><code>az group list -o table\n</code></pre>"},{"location":"azure-data-lake-terraform/#3-executar-o-terraform","title":"3. Executar o Terraform","text":""},{"location":"azure-data-lake-terraform/#31-inicializar-o-terraform","title":"3.1 Inicializar o Terraform","text":"<pre><code>terraform init\n</code></pre>"},{"location":"azure-data-lake-terraform/#32-validar-o-codigo-nos-arquivos-tf","title":"3.2 Validar o c\u00f3digo nos arquivos .tf","text":"<pre><code>terraform validate\n</code></pre>"},{"location":"azure-data-lake-terraform/#33-ajustar-a-formatacao-nos-arquivos-tf","title":"3.3 Ajustar a formata\u00e7\u00e3o nos arquivos .tf","text":"<pre><code>terraform fmt\n</code></pre>"},{"location":"azure-data-lake-terraform/#34-criar-um-plano-de-execucao","title":"3.4 Criar um plano de execu\u00e7\u00e3o","text":"<pre><code>terraform plan\n</code></pre>"},{"location":"azure-data-lake-terraform/#35-aplicar-o-terraform-na-nuvem","title":"3.5 Aplicar o Terraform na nuvem","text":"<pre><code>terraform apply\n</code></pre>"},{"location":"azure-data-lake-terraform/#4-verificar-o-deploy-do-adls-e-do-sql-server","title":"4. Verificar o deploy do ADLS e do SQL Server","text":"<ul> <li>Fa\u00e7a login em Portal Azure e verifique o ADLS e o SQL Server criado.</li> <li>Liberar IP no firewall do SQL Server nas configura\u00e7\u00f5es de rede</li> </ul>"},{"location":"contribuitors/","title":"Contribuidores","text":"<p>Aqui est\u00e3o os membros da equipe que contribu\u00edram para este projeto:</p> <ul> <li>Christian Giuliani</li> <li>GitHub: @Xiristian</li> <li> <p>Contribui\u00e7\u00f5es: Integra\u00e7\u00e3o de todas as partes e Gerenciamento do Projeto.</p> </li> <li> <p>Luz Brenda Oliveira</p> </li> <li>GitHub: @luzbrendaoliv</li> <li> <p>Contribui\u00e7\u00f5es: Documenta\u00e7\u00e3o Mkdocs.</p> </li> <li> <p>Ana Carolina Machado</p> </li> <li>GitHub: @anacarolina1002</li> <li> <p>Contribui\u00e7\u00f5es:  Scripts de cria\u00e7\u00e3o das tabelas e popula\u00e7\u00e3o.</p> </li> <li> <p>Julia Colombo De Luca</p> </li> <li>GitHub: @judwluca</li> <li> <p>Contribui\u00e7\u00f5es: Documenta\u00e7\u00e3o Mkdocs e ReadMe.</p> </li> <li> <p>Bruna P Peruch</p> </li> <li>GitHub: @brupperuch</li> <li> <p>Contribui\u00e7\u00f5es: Aquivo Power BI para cria\u00e7\u00e3o dos Dashboard.</p> </li> <li> <p>Guilherme Brito Pizzollo</p> </li> <li>GitHub: @guilhermebp030504</li> <li> <p>Contribui\u00e7\u00f5es: Configura\u00e7\u00e3o Data Lake e SQLs KPI.</p> </li> <li> <p>Wallace da Silva Mendes</p> </li> <li>GitHub: @WallaceB2</li> <li> <p>Contribui\u00e7\u00f5es: Configura\u00e7\u00e3o Ambiente Data Lake e Terraform.</p> </li> <li> <p>Rafael Carvalho</p> </li> <li>GitHub: @Rafael171022</li> <li>Contribui\u00e7\u00f5es: Configura\u00e7\u00e3o dos Scripts de popula\u00e7\u00e3o da gold e montagens das Kpis.</li> </ul>"},{"location":"dimensional_model/","title":"Modelo Dimensional","text":""},{"location":"environment_setup/","title":"Configura\u00e7\u00e3o do Ambiente","text":""},{"location":"environment_setup/#passo-a-passo-databricks","title":"Passo a passo Databricks:","text":"<ol> <li> <p>Criar um Fork do reposit\u00f3rio atual</p> <ul> <li>Acesse o reposit\u00f3rio no GitHub que voc\u00ea deseja clonar.</li> <li>Clique no bot\u00e3o \"Fork\" no canto superior direito da p\u00e1gina do reposit\u00f3rio.</li> <li>Siga as instru\u00e7\u00f5es para criar um fork do reposit\u00f3rio em sua pr\u00f3pria conta do GitHub.</li> </ul> </li> <li> <p>Conectar conta do Databricks com GitHub</p> <ul> <li>Para conectar sua conta do Databricks com o GitHub, siga as instru\u00e7\u00f5es detalhadas no documento oficial da Databricks: Get Access Tokens from Git Provider</li> <li>Este guia ir\u00e1 ajud\u00e1-lo a gerar tokens de acesso e configurar a integra\u00e7\u00e3o entre o Databricks e o GitHub.</li> </ul> </li> </ol>"},{"location":"ingestion/","title":"Ingest\u00e3o de Dados","text":""},{"location":"ingestion/#ingestao-de-dados","title":"Ingest\u00e3o de Dados:","text":"<ol> <li> <p>Abrir script 'Gerar dados' dentro do Databricks</p> <ul> <li>Navegue at\u00e9 o script chamado 'Gerar dados' no seu workspace do Databricks.</li> <li>Abra o script.</li> </ul> </li> <li> <p>Executar todos os blocos</p> <ul> <li>Execute todos os blocos do script 'Gerar dados' para gerar os dados necess\u00e1rios.</li> </ul> </li> <li> <p>Abrir script 'Landing zone'</p> <ul> <li>Navegue at\u00e9 o script chamado 'Landing zone' no seu workspace do Databricks.</li> <li>Abra o script.</li> </ul> </li> <li> <p>Configurar vari\u00e1veis</p> <ul> <li>Configure a vari\u00e1vel <code>account_name</code> com o nome do Data Lake criado.</li> <li>Configure a vari\u00e1vel <code>sas_token</code> com o token do Data Lake. Para gerar o token, siga as instru\u00e7\u00f5es no link: Generate SAS Token</li> </ul> </li> <li> <p>Executar todos os blocos</p> <ul> <li>Execute todos os blocos do script 'Landing zone' para processar os dados.</li> </ul> </li> </ol>"},{"location":"installation/","title":"Instala\u00e7\u00e3o","text":"<p>Siga as instru\u00e7\u00f5es abaixo para instalar o PetitGato.</p>"},{"location":"installation/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Python 3.6+</li> <li>Git</li> </ul>"},{"location":"installation/#passos-para-instalacao","title":"Passos para Instala\u00e7\u00e3o","text":"<ol> <li>Clone o reposit\u00f3rio:</li> </ol> <pre><code>git clone https://github.com/Xiristian/PetitGato.git\ncd PetitGato\n</code></pre>"},{"location":"introduction/","title":"Introdu\u00e7\u00e3o","text":""},{"location":"introduction/#contexto-do-projeto","title":"Contexto do Projeto","text":"<p>O PetitGato \u00e9 um sistema desenvolvido para gerenciar uma cafeteria tem\u00e1tica com gatos. A cafeteria permite que os clientes desfrutem de uma boa x\u00edcara de caf\u00e9 enquanto interagem com gatos. Este documento fornece uma vis\u00e3o geral do projeto, seus objetivos e suas principais funcionalidades.</p>"},{"location":"introduction/#objetivos","title":"Objetivos","text":"<p>O principal objetivo deste projeto \u00e9 implementar um pipeline de dados robusto que permita monitorar e analisar indicadores chave de desempenho (KPIs) relacionados \u00e0 opera\u00e7\u00e3o da cafeteria e ao cuidado com os gatos.</p> <p>Para uma vis\u00e3o detalhada do sistema, veja a Vis\u00e3o Geral do Sistema.</p>"},{"location":"overview/","title":"Vis\u00e3o Geral do Pipeline","text":"<p>O pipeline de dados \u00e9 composto de v\u00e1rias etapas que processam os dados desde a extra\u00e7\u00e3o at\u00e9 o carregamento final.</p>"},{"location":"overview/#arquitetura","title":"Arquitetura","text":"<ol> <li>Extra\u00e7\u00e3o: Coleta de dados de v\u00e1rias fontes.</li> <li>Transforma\u00e7\u00e3o: Processamento e transforma\u00e7\u00e3o dos dados.</li> <li>Carregamento: Armazenamento dos dados transformados em destinos finais.</li> </ol>"},{"location":"overview/#diagrama-do-pipeline","title":"Diagrama do Pipeline","text":""},{"location":"overview/#componentes","title":"Componentes","text":"<ul> <li>Iniciando Ambiente</li> <li>Ingest\u00e3o de Dados</li> <li>Transforma\u00e7\u00e3o de Dados com Apache</li> </ul>"}]}